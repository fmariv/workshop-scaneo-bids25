{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Labelling with SCANEO\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now that we understood a bit about the EOTDL and it's capabilities, we are going to use a small dataset specifically created and curated to showcase the capabilities of SCANEO.\n",
            "\n",
            "To do this, we first need to prepare the training and test set using the EOTDL CLI. This may take a little time the first time, so be patient!\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Staging assets: 100%|███████████████████████████| 12/12 [00:15<00:00,  1.28s/it]\n",
                  "Data available at ./SCANEO\n"
               ]
            }
         ],
         "source": [
            "!uv run eotdl models get SCANEO -p . -a -f   # Como path le damos el directorio del proyecto,\n",
            "                                              # -a para que se descarguen los archivos STAC\n",
            "                                              # -f para que se fuerce la descarga"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we have our dataset, let's label it!\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# !uv add scaneo"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "You can run `scaneo` with the following options.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\u001b[1m                                                                                \u001b[0m\n",
                  "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mscaneo [OPTIONS]\u001b[0m\u001b[1m                                                       \u001b[0m\u001b[1m \u001b[0m\n",
                  "\u001b[1m                                                                                \u001b[0m\n",
                  "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
                  "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-port\u001b[0m                \u001b[1;32m-p\u001b[0m      \u001b[1;33mINTEGER\u001b[0m  Port to run the server on             \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m                                        \u001b[2m[default: 8000]          \u001b[0m             \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-host\u001b[0m                \u001b[1;32m-h\u001b[0m      \u001b[1;33mTEXT   \u001b[0m  Host to run the server on             \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m                                        \u001b[2m[default: localhost]     \u001b[0m             \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-workers\u001b[0m             \u001b[1;32m-w\u001b[0m      \u001b[1;33mINTEGER\u001b[0m  Number of workers to run the server   \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m                                        on                                    \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-version\u001b[0m             \u001b[1;32m-v\u001b[0m      \u001b[1;33m       \u001b[0m  Print the version and exit            \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-install\u001b[0m\u001b[1;36m-completion\u001b[0m          \u001b[1;33m       \u001b[0m  Install completion for the current    \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m                                        shell.                                \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m\u001b[1;36m-completion\u001b[0m             \u001b[1;33m       \u001b[0m  Show completion for the current       \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m                                        shell, to copy it or customize the    \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m                                        installation.                         \u001b[2m│\u001b[0m\n",
                  "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                        \u001b[1;33m       \u001b[0m  Show this message and exit.           \u001b[2m│\u001b[0m\n",
                  "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                  "\n"
               ]
            }
         ],
         "source": [
            "!uv run scaneo --help"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "You can run `scan` by opening a terminal and running:\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!uv run scaneo"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "You can then access the web interface at `http://localhost:8000`.\n",
            "\n",
            "> You can change the host and port with `scan --host 0.0.0.0 --port 8000`.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "![scaneo](images/scaneo.png)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## AI-assisted labeling\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Once we've played with the labeling tools, we can try SCANEO's best feature: adding and integrating your own models to automatically label the training set. As you can imagine, this significantly speeds up labeling times.\n",
            "\n",
            "First, we need to deploy the SCANEO inference API. To do this, we'll do the following:\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Cloning into 'scaneo-api'...\n",
                  "remote: Enumerating objects: 4098, done.\u001b[K\n",
                  "remote: Counting objects: 100% (1085/1085), done.\u001b[K\n",
                  "remote: Compressing objects: 100% (729/729), done.\u001b[K\n",
                  "remote: Total 4098 (delta 409), reused 861 (delta 272), pack-reused 3013 (from 1)\u001b[K\n",
                  "Receiving objects: 100% (4098/4098), 26.46 MiB | 19.64 MiB/s, done.\n",
                  "Resolving deltas: 100% (2082/2082), done.\n"
               ]
            }
         ],
         "source": [
            "!git clone https://github.com/earthpulse/scaneo scaneo-api"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we copy the model from `SCANEO/models/` to `scaneo-api/inference/`\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "cp -rf SCANEO/models scaneo-api/inference"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We can take a look into the API before launching it. At to launch it, it is as simple as the following command:\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "!cd scaneo-api && make inference"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now we can go to the inference API at http://0.0.0.0:8001/docs. The road segmentation model with Sentinel-2 imagery is at http://0.0.0.0:8001/s2-roads\n",
            "\n",
            "Now, to activate our model, we must follow these steps:\n",
            "\n",
            "1. Go to http://localhost:8000/models and create a new model.\n",
            "2. Give it a name and description, which can be something related to `BiDS 2025`, and set the URL to `http://0.0.0.0:8001/s2-roads`. The task is segmentation. No further action is required.\n",
            "3. Now, go to our campaign, to the settings section, and add our model. It is important to note that for it to work correctly, we must set the `roads` class to 1 and leave the others empty, with no value, not even 0. And save.\n",
            "4. We return to the campaign, select an image, the \"roads\" class, and in the top left tab, click \"Run inference model.\" And voilà! Labeling!\n",
            "\n",
            "With this, the advantages are clear. You can label a small dataset, train a model, and use the same model to continue labeling the training set, iteratively, making it much faster.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We have done this using the `RoadSegmentation` segmentation model to automatically segmentate roads, but we can use other pre-configured models, such as for cloud masking! To do so, we first need to stage the cloud masking model from the [CloudSEN12L2A](https://www.eotdl.com/models/CloudSEN12L2A) model.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Staging assets: 100%|█████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\n",
                  "Data available at ./CloudSEN12L2A\n"
               ]
            }
         ],
         "source": [
            "!uv run eotdl models get CloudSEN12L2A -p . -a"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Now, let's add it to the inference API\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "!cp CloudSEN12L2A/L2A_EfficientNetUnet.pt scaneo-api/inference/"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "And restart the inference API to use it! Isn't it wonderful?\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Opportunities for discussion and contribution\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Feel free to ask questions now (live or via Discord) and suggest future improvements.\n",
            "\n",
            "- What do you think about the AI-assisted label capabilities?\n",
            "- Do you think is something you need? If not, why?\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.8"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
